{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ccfb16",
   "metadata": {},
   "source": [
    "# 02 — Data Preprocessing (Dual Pipeline)\n",
    "\n",
    "This notebook prepares TWO variations of the dataset:\n",
    "1. **Standard**: Basic cleaning (lowercase, remove URLs/emojis).\n",
    "2. **Irony-Augmented**: Standard cleaning + `[IRONIA]` tagging for detected colloquialisms.\n",
    "\n",
    "**Output Locations**:\n",
    "- `../data/processed/standard/`\n",
    "- `../data/processed/irony/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25d27b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:20.635488Z",
     "iopub.status.busy": "2026-02-14T20:16:20.634982Z",
     "iopub.status.idle": "2026-02-14T20:16:24.294313Z",
     "shell.execute_reply": "2026-02-14T20:16:24.292247Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Ensure data directories exist\n",
    "os.makedirs('../data/processed/standard', exist_ok=True)\n",
    "os.makedirs('../data/processed/irony', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc07b083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:24.298572Z",
     "iopub.status.busy": "2026-02-14T20:16:24.297895Z",
     "iopub.status.idle": "2026-02-14T20:16:24.347144Z",
     "shell.execute_reply": "2026-02-14T20:16:24.345096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.12\n",
      "IPython version      : 9.10.0\n",
      "\n",
      "numpy  : 1.26.4\n",
      "pandas : 3.0.0\n",
      "sklearn: 1.8.0\n",
      "emoji  : 2.15.0\n",
      "\n",
      "Compiler    : Clang 17.0.0 (clang-1700.6.3.2)\n",
      "OS          : Darwin\n",
      "Release     : 25.2.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,pandas,sklearn,emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238791c",
   "metadata": {},
   "source": [
    "## 1. Load Data & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18205725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:24.350959Z",
     "iopub.status.busy": "2026-02-14T20:16:24.350615Z",
     "iopub.status.idle": "2026-02-14T20:16:24.441513Z",
     "shell.execute_reply": "2026-02-14T20:16:24.440134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 samples\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/corpus.csv')\n",
    "df['quote_safe'] = df['QuoteText'].fillna('')\n",
    "df['text'] = df.apply(lambda x: (x['quote_safe'] + \" \" + x['TweetText']).strip(), axis=1)\n",
    "df['label'] = df['Categorization']\n",
    "df = df[['text', 'label']]\n",
    "print(f\"Loaded {df.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaba4d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:24.445635Z",
     "iopub.status.busy": "2026-02-14T20:16:24.445235Z",
     "iopub.status.idle": "2026-02-14T20:16:24.453975Z",
     "shell.execute_reply": "2026-02-14T20:16:24.452835Z"
    }
   },
   "outputs": [],
   "source": [
    "def tag_irony_logic(text):\n",
    "    if not isinstance(text, str): return text\n",
    "    # Laughs\n",
    "    text = re.sub(r'(?i)\\b(j+a+){2,}\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\b(j+e+){2,}\\b', ' [IRONIA] ', text)\n",
    "    # Specific phrases\n",
    "    text = re.sub(r'\\(\\?+\\)?', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bx+d+\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\b(a+h? ?r+e+)\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bare\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bbue\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bwe\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bbueno no\\b', ' [IRONIA] ', text)\n",
    "    text = re.sub(r'(?i)\\bno bueno\\b', ' [IRONIA] ', text)\n",
    "    return text\n",
    "\n",
    "def clean_base(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    # Demojize\n",
    "    text = emoji.demojize(text, language='es', delimiters=(\" :\", \": \"))\n",
    "    # Lowercase EXCEPT tags\n",
    "    parts = re.split(r'(\\[[A-ZÁÉÍÓÚÑ]+\\])', text)\n",
    "    processed = []\n",
    "    for part in parts:\n",
    "        if re.match(r'^\\[[A-ZÁÉÍÓÚÑ]+\\]$', part):\n",
    "            processed.append(part)\n",
    "        else:\n",
    "            processed.append(part.lower())\n",
    "    text = \"\".join(processed)\n",
    "    # Whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def process_standard(text):\n",
    "    return clean_base(text)\n",
    "\n",
    "def process_irony(text):\n",
    "    # Tag irony FIRST, then clean (so [IRONIA] is preserved as uppercase tag)\n",
    "    text = tag_irony_logic(text)\n",
    "    return clean_base(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d75e3d",
   "metadata": {},
   "source": [
    "## 2. Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed42d380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:24.457188Z",
     "iopub.status.busy": "2026-02-14T20:16:24.456874Z",
     "iopub.status.idle": "2026-02-14T20:16:25.528448Z",
     "shell.execute_reply": "2026-02-14T20:16:25.527289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Standard: que ganas de tomarme una línea. la del 59, que me lleva a mi casa.\n",
      "Sample Irony:    que ganas de tomarme una línea. la del 59, que me lleva a mi casa.\n"
     ]
    }
   ],
   "source": [
    "# Standard\n",
    "df_standard = df.copy()\n",
    "df_standard['text_clean'] = df_standard['text'].apply(process_standard)\n",
    "\n",
    "# Irony\n",
    "df_irony = df.copy()\n",
    "df_irony['text_clean'] = df_irony['text'].apply(process_irony)\n",
    "\n",
    "print(\"Sample Standard:\", df_standard['text_clean'].iloc[10])\n",
    "print(\"Sample Irony:   \", df_irony['text_clean'].iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac327a5",
   "metadata": {},
   "source": [
    "## 3. Split and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503c15df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T20:16:25.532950Z",
     "iopub.status.busy": "2026-02-14T20:16:25.532538Z",
     "iopub.status.idle": "2026-02-14T20:16:25.618960Z",
     "shell.execute_reply": "2026-02-14T20:16:25.617611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Standard splits to ../data/processed/standard\n",
      "Saved Irony splits to ../data/processed/irony\n"
     ]
    }
   ],
   "source": [
    "def save_splits(dataframe, name, output_dir):\n",
    "    train, temp = train_test_split(dataframe, test_size=0.3, stratify=dataframe['label'], random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=0.5, stratify=temp['label'], random_state=42)\n",
    "    \n",
    "    train.to_csv(f'{output_dir}/train.csv', index=False)\n",
    "    val.to_csv(f'{output_dir}/val.csv', index=False)\n",
    "    test.to_csv(f'{output_dir}/test.csv', index=False)\n",
    "    print(f\"Saved {name} splits to {output_dir}\")\n",
    "\n",
    "save_splits(df_standard, \"Standard\", \"../data/processed/standard\")\n",
    "save_splits(df_irony, \"Irony\", \"../data/processed/irony\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
